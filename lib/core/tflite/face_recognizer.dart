// lib/core/tflite/face_recognizer.dart
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';

import 'package:flutter/services.dart';
import 'package:image/image.dart' as img;
import 'package:tflite_flutter/tflite_flutter.dart';

const int _inputSize = 112;
const int _outputSize = 192;

class FaceRecognizer {
  late Interpreter _interpreter;
  static const String _modelPath = 'assets/face_recognition.map';

  static final FaceRecognizer _instance = FaceRecognizer._internal();
  factory FaceRecognizer() => _instance;
  FaceRecognizer._internal();

  final Float32List _inputBuffer = Float32List(_inputSize * _inputSize * 3);

  /// Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø§Ø² assets
  Future<void> loadModel() async {
    try {
      final modelData = await rootBundle.load(_modelPath);
      final interpreter = Interpreter.fromBuffer(
        modelData.buffer.asUint8List(),
      );
      _interpreter = interpreter;
      print('âœ… TFLite model loaded successfully from assets: $_modelPath');
    } catch (e) {
      print('âŒ Failed to load TFLite model: $e');
      rethrow;
    }
  }

  /// Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø§Ù‚Ù„ÛŒØ¯Ø³ÛŒ (L2 distance)
  double _calculateDistance(List<double> emb1, List<double> emb2) {
    double sum = 0.0;
    for (int i = 0; i < emb1.length; i++) {
      final diff = emb1[i] - emb2[i];
      sum += diff * diff;
    }
    return sqrt(sum);
  }

  /// Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø³ÛŒÙ†ÙˆØ³ÛŒ (Cosine Similarity)
  double _calculateCosineSimilarity(List<double> emb1, List<double> emb2) {
    double dotProduct = 0.0;
    double normA = 0.0;
    double normB = 0.0;

    for (int i = 0; i < emb1.length; i++) {
      dotProduct += emb1[i] * emb2[i];
      normA += emb1[i] * emb1[i];
      normB += emb2[i] * emb2[i];
    }

    if (normA == 0 || normB == 0) return 0.0;
    return dotProduct / (sqrt(normA) * sqrt(normB));
  }

  /// Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø¯Ø§Ø± (L2 Normalization)
  List<double> _normalizeEmbedding(List<double> embedding) {
    double norm = 0.0;
    for (final value in embedding) {
      norm += value * value;
    }
    norm = sqrt(norm);

    if (norm == 0) return embedding;

    return embedding.map((value) => value / norm).toList();
  }

  /// Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±: ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ + Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ [-1, 1]
  Float32List _preProcess(img.Image image) {
    final resizedImage = img.copyResize(
      image,
      width: _inputSize,
      height: _inputSize,
    );
    const double imageMean = 127.5;
    const double imageStd = 127.5;
    int pixelIndex = 0;

    _inputBuffer.fillRange(0, _inputBuffer.length, 0.0);

    for (int y = 0; y < _inputSize; y++) {
      for (int x = 0; x < _inputSize; x++) {
        final pixel = resizedImage.getPixel(x, y);

        final r = pixel.r.toInt();
        final g = pixel.g.toInt();
        final b = pixel.b.toInt();

        _inputBuffer[pixelIndex++] = (r - imageMean) / imageStd;
        _inputBuffer[pixelIndex++] = (g - imageMean) / imageStd;
        _inputBuffer[pixelIndex++] = (b - imageMean) / imageStd;
      }
    }
    return _inputBuffer;
  }

  /// Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ (Embedding) Ø§Ø² ØªØµÙˆÛŒØ±
  Future<List<double>?> getFaceEmbedding(String imagePath) async {
    try {
      print('ğŸ“¸ Processing image: $imagePath');

      final bytes = File(imagePath).readAsBytesSync();
      final originalImage = img.decodeImage(bytes);
      if (originalImage == null) {
        print('âŒ Failed to decode image: $imagePath');
        return null;
      }

      final inputTensor = _preProcess(originalImage);
      final outputBuffer = Float32List(_outputSize);
      final outputMap = {0: outputBuffer};

      _interpreter.run(inputTensor, outputMap);

      // Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ embedding
      final normalizedEmbedding = _normalizeEmbedding(
        outputBuffer.toList(growable: false),
      );

      print(
        'âœ… Embedding extracted successfully (${normalizedEmbedding.length} dimensions)',
      );
      return normalizedEmbedding;
    } catch (e) {
      print('âŒ Error running inference: $e');
      return null;
    }
  }

  /// Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¯Ùˆ Ú†Ù‡Ø±Ù‡
  Future<bool> compare(
    String liveImagePath,
    List<double> savedEmbedding,
  ) async {
    print('ğŸ” Starting face comparison...');

    final liveEmbedding = await getFaceEmbedding(liveImagePath);

    if (liveEmbedding == null) {
      print('âŒ Failed to extract embedding from live image.');
      return false;
    }

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø§Ù‚Ù„ÛŒØ¯Ø³ÛŒ
    final distance = _calculateDistance(liveEmbedding, savedEmbedding);

    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¨Ø§Ù‡Øª Ú©Ø³ÛŒÙ†ÙˆØ³ÛŒ
    final cosineSim = _calculateCosineSimilarity(liveEmbedding, savedEmbedding);

    // Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªÙ†Ø¸ÛŒÙ…
    const double distanceThreshold = 1.0; // Ú©Ù…ØªØ± = ÛŒÚ©Ø³Ø§Ù†â€ŒØªØ±
    const double cosineThreshold = 0.5; // Ø¨ÛŒØ´ØªØ± = ÛŒÚ©Ø³Ø§Ù†â€ŒØªØ±

    print(
      'ğŸ“Š Distance: ${distance.toStringAsFixed(4)} (threshold: $distanceThreshold)',
    );
    print(
      'ğŸ“Š Cosine Similarity: ${cosineSim.toStringAsFixed(4)} (threshold: $cosineThreshold)',
    );

    // Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‡Ø± Ø¯Ùˆ Ù…Ø¹ÛŒØ§Ø± Ø¨Ø±Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
    final isMatch =
        (distance <= distanceThreshold) && (cosineSim >= cosineThreshold);

    print(
      isMatch
          ? 'âœ… MATCH - Faces are the same person!'
          : 'âŒ NO MATCH - Different persons',
    );

    return isMatch;
  }

  /// Ø¢Ø²Ø§Ø¯Ø³Ø§Ø²ÛŒ Ù…Ù†Ø§Ø¨Ø¹
  void close() {
    _interpreter.close();
  }
}
